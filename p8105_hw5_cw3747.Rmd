---
title: "p8105_hw5_cw3747"
author: "chuhan wang_cw3747"
date: "2025-11-04"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(patchwork)
library(scales)
library(dplyr)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem1

### Birthday Function
```{r}
library(ggplot2)
library(dplyr)

set.seed(123)


birthday_dup <- function(n, days = 365) {
  bdays <- sample.int(days, n, replace = TRUE) 
  any(duplicated(bdays))                       
}
```


### iteration
```{r}
simulate_prob <- function(n, B = 10000, days = 365) {
  mean(replicate(B, birthday_dup(n, days)))
}

ns <- 2:50
B  <- 10000

probs <- numeric(length(ns))
for (i in seq_along(ns)) {
  probs[i] <- simulate_prob(ns[i], B = B)
}

df_loop <- data.frame(n = ns, p = probs)

n50_loop <- min(df_loop$n[df_loop$p >= 0.5])
```

### ggplot
```{r}
ggplot(df_loop, aes(n, p)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.5) +
  geom_hline(yintercept = 0.5, linetype = 2) +
  geom_vline(xintercept = n50_loop, linetype = 2) +
  annotate("text", x = n50_loop + 1, y = 0.52,
           label = paste0("~50% at n = ", n50_loop), hjust = 0) +
  labs(title = "P(at least one shared birthday) vs. Group size",
       x = "Group size (n)", y = "Probability") +
  theme_minimal(base_size = 12)
```

The plot shows that the probability of at least one shared birthday increases rapidly with group size. Around n = 23, the probability reaches about 0.5, meaning that in a random group of 23 people there is 50% chance that some pair shares a birthday (this does not mean that “half of the people” have a match). As n approaches 50, the probability nears 1, implying that a shared-birthday pair is almost guaranteed, though not that everyone finds a match. Real-world seasonality and clustering can shift the curve slightly, but the qualitative “birthday paradox” pattern remains.


## Problem2

### set function
```{r}
library(broom) 

set.seed(123)

sim_once <- function(mu, n = 30, sigma = 5) {
  x  <- rnorm(n, mean = mu, sd = sigma)
  tt <- t.test(x, mu = 0)
  tibble(
    mu = mu,
    mu_hat = mean(x),
    p = tidy(tt)$p.value,
    reject = p < 0.05
  )
}
```

### iteration
```{r}
simulate_mu <- function(mu, B = 5000, n = 30, sigma = 5) {
  bind_rows(replicate(B, sim_once(mu, n, sigma), simplify = FALSE))
}
```

### for different $\mu$
```{r}
mus <- 0:6
res_list <- vector("list", length(mus))
for (i in seq_along(mus)) {
  res_list[[i]] <- simulate_mu(mus[i], B = 5000)
}
res <- bind_rows(res_list)
```

### power of test
```{r}
summ <- res |>
  group_by(mu) |>
  summarise(
    power = mean(reject),
    avg_mu_hat_all = mean(mu_hat),
    avg_mu_hat_rej = mean(mu_hat[reject]),
    .groups = "drop"
  )

ggplot(summ, aes(mu, power)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.6) +
  geom_hline(yintercept = 0.05, linetype = 2) +
  labs(title = "Power of t-test",
       x = "True mean (μ)", y = "Power") +
  theme_minimal(base_size = 12)
```

We fix $\mu_0 = 0$ and $\sigma = 5$. The effect size is $d = (\mu - \mu_0) / \sigma$. Hence, larger $\mu$ implies a larger effect size. The plot shows that power increases monotonically with $\mu$: at $\mu$ = 0, the the rejection rate is about the rejection rate is about $\alpha$ = 0.05; as $\mu$ grows, power rises quickly. Larger effect size makes the sample mean more distinct from 0, yielding a larger absolute t-statistic and a higher chance of rejecting the null.

### average estimate
```{r}
summ_long <- summ |>
  pivot_longer(-mu, names_to = "metric", values_to = "value") |>
  filter(metric %in% c("avg_mu_hat_all","avg_mu_hat_rej"))

ggplot(summ_long, aes(mu, value, color = metric)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.6) +
  geom_abline(slope = 1, intercept = 0, linetype = 3) +
  scale_color_discrete(labels = c("Overall E[μ̂]", "E[μ̂ | reject]")) +
  labs(title = "Average estimate of μ̂ vs true μ",
       x = "True mean (μ)", y = "Average μ̂", color = "") +
  theme_minimal(base_size = 12)
```

The sample average of $\hat{\mu}$ among tests that reject $H_0$ is not approximately equal to the true $\mu$. We can see from the plot, when the $\mu$ is around 1, conditioning on significance selects extreme estimates, so the $\hat{\mu}$ shifted away from 0. It's like a form of selection bias. Only when the power is very high so that almost all samples reject $H_0$, $\mu$ and $\hat{\mu}$ are close.

## Problem3

### data import
```{r}
homicide = read_csv("./homicide-data.csv") |>
  janitor::clean_names() |>
  mutate(reported_date = ymd(reported_date))
```

### describe
```{r}
glimpse(homicide)
count(homicide, disposition, sort = TRUE)
count(homicide, city, state, sort = TRUE) |> head(10)

n_rows   <- nrow(homicide)
n_cols   <- ncol(homicide)
n_cities <- dplyr::n_distinct(homicide$city)
n_states <- dplyr::n_distinct(homicide$state)

date_min <- suppressWarnings(min(homicide$reported_date, na.rm = TRUE))
date_max <- suppressWarnings(max(homicide$reported_date, na.rm = TRUE))

unsolved_flag <- homicide$disposition %in% c("Closed without arrest","Open/No arrest")
n_unsolved    <- sum(unsolved_flag, na.rm = TRUE)

top_cities <- homicide |>
  count(city, state, sort = TRUE) |>
  mutate(city_state = paste0(city, ", ", state)) |>
  slice_head(n = 5)
```

The raw homicide dataset contains `r n_rows` observations and `r n_cols` variables collected from `r n_cities` cities across `r n_states` states.
The data span from `r date_min` to `r date_max`. And treating “Closed without arrest” and “Open/No arrest” as unsolved, there are `r n_unsolved` unsolved cases of all records.
Cities with the most cases include `r top_cities$city_state[1]` (`r top_cities$n[1]`), `r top_cities$city_state[2]` (`r top_cities$n[2]`), and `r top_cities$city_state[3]` (`r top_cities$n[3]`).

### city state
```{r}
library(stringr)

city_summary <- homicide |>
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) |>
  group_by(city_state) |>
  summarise(
    total_homicides    = n(),
    unsolved_homicides = sum(unsolved, na.rm = TRUE),
    solved_homicides   = total_homicides - unsolved_homicides,
    pct_unsolved       = unsolved_homicides / total_homicides
  ) |>
  arrange(desc(total_homicides))
```

```{r}
overall <- homicide |>
  mutate(unsolved = disposition %in% c("Closed without arrest","Open/No arrest")) |>
  summarise(
    total = n(),
    unsolved = sum(unsolved, na.rm = TRUE),
    pct = unsolved / total
  )

top_tot <- city_summary |> slice_max(total_homicides, n = 1)
top_uns <- city_summary |> slice_max(unsolved_homicides, n = 1)
```

There are `r nrow(city_summary)` cities in the dataset. Overall, we observe `r overall$total` homicides, of which `r overall$unsolved` (`r scales::percent(overall$pct, 0.1)`) are unsolved.
The city with the most homicides is `r top_tot$city_state` (`r top_tot$total_homicides` cases), and it also has `r top_tot$unsolved_homicides` unsolved cases (`r scales::percent(top_tot$pct_unsolved, 0.1)`).

### prop test fot bal
```{r}
library(broom)

balt_row <- city_summary %>% 
  filter(city_state == "Baltimore, MD") %>%
  select(x = unsolved_homicides, n = total_homicides)


balt_row

pt_balt <- prop.test(pull(balt_row, x), pull(balt_row, n))  #save the output of prop.test as an R object

balt_res <- tidy(pt_balt) |>
  select(p_hat = estimate, conf_low = conf.low, conf_high = conf.high)

balt_res

p_hat <- balt_res$p_hat; ci_lo <- balt_res$conf_low; ci_hi <- balt_res$conf_high
```

In Baltimore, MD, the estimated proportion of unsolved homicides is `r scales::percent(p_hat, 0.1)`, 95% CI `r scales::percent(ci_lo, 0.1)`–`r scales::percent(ci_hi, 0.1)`.

### prop test for all

```{r}
library(purrr)

city_prop_all <- city_summary |>
  transmute(
    city_state,
    x = unsolved_homicides,
    n = total_homicides
  ) |>
  mutate(
    pt_obj = map2(x, n, ~ prop.test(.x, .y))
  ) |>
  mutate(
    pt_tidy = map(pt_obj, tidy)
  ) |>
  select(city_state, pt_tidy) |>
  tidyr::unnest(pt_tidy) |>
   transmute(
    city_state,
    p_hat    = estimate,
    conf_low = conf.low,
    conf_high= conf.high
  )

```

```{r}
library(knitr)

knitr::kable(
  city_prop_all |> dplyr::arrange(desc(p_hat)),
  caption = "Estimated proportion of unsolved homicides and 95% CI by city"
)
```
